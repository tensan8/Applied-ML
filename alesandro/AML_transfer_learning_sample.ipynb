{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reference:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning"
      ],
      "metadata": {
        "id": "KRIlPuhbtue5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "90GFjnEDt1lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning (Pre-Trained Model)"
      ],
      "metadata": {
        "id": "goofC6Kxa913"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the solutions that we can try in order to have a good model without the need to train our own model for a really long time is to use a pre-trained model using transfer learning. A pre-trained model is basically a model that has been structured, trained, and tested using different kind of big dataset thus the model is robust enough to be directly used. A pre-trained model can be simply loaded to a project and get fine-tuned or trained again using the available dataset in order to adjust its knowledge to the dataset that we are working on. In this case, we will utilize the MobileNetV2 pre-trained model to help us in getting better accuracy with less amount of training efforts needed."
      ],
      "metadata": {
        "id": "t-hiQH5eRMaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the required libraries\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import preprocess_input"
      ],
      "metadata": {
        "id": "olxYZBsx5Srw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A pre-trained model usually comes with pre-defined format of dataset that is suitable for the model.\n",
        "# In this case, MobileNetV2 has some size options that we can choose from and in this case we will go with 128x128 size of image\n",
        "# By that, we will load the dataset again but now, we will use different size of data. The other process is the same as the one that we have worked on before.\n",
        "x_train_dataset = list()\n",
        "\n",
        "for name in image_name:\n",
        "  image_data = image.imread('Train/' + name)\n",
        "  image_data = tf.cast(image_data, tf.float32)/255\n",
        "  image_data = tf.image.resize(image_data, (128, 128), method= 'bilinear')\n",
        "  x_train_dataset.append(image_data)\n",
        "train_data = np.array(x_train_dataset)\n",
        "\n",
        "y_train_np = np.array(label)\n",
        "train_labels = to_categorical(y_train_np)"
      ],
      "metadata": {
        "id": "8h1n4px-67lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remember to split the data into 80-20 train-validation dataset so we can know how the model perform later on\n",
        "x_train, x_validation, y_train, y_validation = train_test_split(train_data, train_labels, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "U0KFp5bO67l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's the load the pre-trained model. We will utilize our own classification layer (Dense(200)) so we need to exclude the top layer of the pre-trained model\n",
        "base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwrrAqTW5p3w",
        "outputId": "ce156516-effa-4c04-c111-fa7587cafd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we wanted to utilize the weights that have been embedded into the pre-trained model to help us in getting higher accuracy with less training,\n",
        "# we will need to ensure that we prevent the model from updating its weight when data was fit into the model. The pre-trained model later on will be\n",
        "# a part of the sequential layer so the layers that will be trained later on will be the extra layers that we add such as the Dense or pooling layer\n",
        "# while the layers that have been embedded into the pre-trained model must be not changed at all.\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "vbPQYN8K7h3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here's how the pre-trained model was structured\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "Kmbge_Kk7kpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e6a5ca-22ec-45ca-afe1-748c55f1c063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenetv2_1.00_128\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 64, 64, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 64, 64, 32)   128         ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 64, 64, 32)   0           ['bn_Conv1[0][0]']               \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 64, 64, 32)  288         ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 64, 64, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 64, 64, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                                                           ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 64, 64, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 64, 64, 16)  64          ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 64, 64, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 64, 64, 96)  384         ['block_1_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 64, 64, 96)   0           ['block_1_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 65, 65, 96)   0           ['block_1_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 32, 32, 96)  864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 32, 32, 96)  384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 32, 32, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 32, 32, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 32, 32, 24)  96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 32, 32, 144)  3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 32, 32, 144)  576        ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 32, 32, 144)  0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 32, 32, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 32, 32, 144)  576        ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 32, 32, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 32, 32, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 32, 32, 24)  96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 32, 32, 24)   0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 32, 32, 144)  3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 32, 32, 144)  576        ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 32, 32, 144)  0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 33, 33, 144)  0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 16, 16, 144)  1296       ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 16, 16, 144)  576        ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 16, 16, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 16, 16, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 16, 16, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 16, 16, 192)  768        ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 16, 16, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 16, 16, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 16, 16, 32)   0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 16, 16, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 16, 16, 192)  768        ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 16, 16, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 16, 16, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 16, 16, 32)   0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 17, 17, 192)  0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 8, 8, 192)   1728        ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 8, 8, 192)   768         ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 8, 8, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 8, 8, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 8, 8, 64)     0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 8, 8, 64)     0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 8, 8, 64)     0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 8, 8, 384)    24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 8, 8, 384)   1536        ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 8, 8, 384)    0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 8, 8, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 8, 8, 384)   1536        ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 8, 8, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 8, 8, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 8, 8, 576)   2304        ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 8, 8, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 8, 8, 96)     0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 8, 8, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 8, 8, 576)   2304        ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 8, 8, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 8, 8, 96)     0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 9, 9, 576)    0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 4, 4, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 4, 4, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 4, 4, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 4, 4, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 4, 4, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 4, 4, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 4, 4, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 4, 4, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 4, 4, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 4, 4, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We have seen on data augmentation helped our model to be better so let's try to add data augmentation into our model again.\n",
        "data_augmentation = Sequential([\n",
        "    RandomFlip('horizontal'),\n",
        "    RandomRotation(0.2)\n",
        "])"
      ],
      "metadata": {
        "id": "OyQj4tCFEyg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then let's initiate our model. We will first initiate the input layers where it will take the numpy array with the size as defined\n",
        "inputs = tf.keras.Input(shape=(128, 128, 3))\n",
        "\n",
        "# We will then augment the image data using the augmentation layers that we have defined above\n",
        "augmented_data = data_augmentation(inputs)\n",
        "\n",
        "# Fit the augmented data to be processed by the pre-trained model which is MobileNetV2\n",
        "pretrained_data = base_model(augmented_data, training=False)\n",
        "\n",
        "# Take the average values of the data using average pooling\n",
        "pooled_data = tf.keras.layers.GlobalAveragePooling2D()(pretrained_data)\n",
        "\n",
        "# Just in case the model starts to overfit because of the small amount of data, let's surpress it a bit using dropout layer\n",
        "dropped_data = Dropout(0.4)(pooled_data)\n",
        "\n",
        "# Then finally we will dense everything to 200 outputs using softmax and some regularizers as we experimented before.\n",
        "outputs = Dense(200, activation = 'softmax', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(dropped_data)\n",
        "\n",
        "# Make the model to flow from the inputs layer to the output layer\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "eUc6Vg2c8FvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwc2oD-2Vud8",
        "outputId": "ff93109b-3260-437a-ced1-956a376e48ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " mobilenetv2_1.00_128 (Funct  (None, 4, 4, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " global_average_pooling2d_7   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 200)               256200    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,514,184\n",
            "Trainable params: 256,200\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=[TopKCategoricalAccuracy(k=1)])"
      ],
      "metadata": {
        "id": "vgphVn0v_ChX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# and train the model to adjust some of the layers to fit the data that we are working on.\n",
        "# we will use less epochs as the model has been pre-trained before so we only need to adjust some weights only\n",
        "history = model.fit(x_train, y_train, epochs = 16, validation_data = (x_validation, y_validation))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYDNGjBK_wtM",
        "outputId": "228fb659-474b-425e-941d-2b088528a657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/16\n",
            "121/121 [==============================] - 9s 49ms/step - loss: 7.6096 - top_k_categorical_accuracy: 0.0549 - val_loss: 6.0017 - val_top_k_categorical_accuracy: 0.1770\n",
            "Epoch 2/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 5.5120 - top_k_categorical_accuracy: 0.2250 - val_loss: 5.1829 - val_top_k_categorical_accuracy: 0.2671\n",
            "Epoch 3/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 4.6418 - top_k_categorical_accuracy: 0.3238 - val_loss: 4.7103 - val_top_k_categorical_accuracy: 0.2857\n",
            "Epoch 4/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 4.1759 - top_k_categorical_accuracy: 0.3919 - val_loss: 4.4713 - val_top_k_categorical_accuracy: 0.2971\n",
            "Epoch 5/16\n",
            "121/121 [==============================] - 5s 39ms/step - loss: 3.8499 - top_k_categorical_accuracy: 0.4320 - val_loss: 4.2544 - val_top_k_categorical_accuracy: 0.3416\n",
            "Epoch 6/16\n",
            "121/121 [==============================] - 5s 39ms/step - loss: 3.6490 - top_k_categorical_accuracy: 0.4639 - val_loss: 4.1594 - val_top_k_categorical_accuracy: 0.3406\n",
            "Epoch 7/16\n",
            "121/121 [==============================] - 5s 39ms/step - loss: 3.5306 - top_k_categorical_accuracy: 0.4817 - val_loss: 4.0574 - val_top_k_categorical_accuracy: 0.3458\n",
            "Epoch 8/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 3.3821 - top_k_categorical_accuracy: 0.5113 - val_loss: 4.0227 - val_top_k_categorical_accuracy: 0.3385\n",
            "Epoch 9/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 3.3209 - top_k_categorical_accuracy: 0.5250 - val_loss: 3.9744 - val_top_k_categorical_accuracy: 0.3602\n",
            "Epoch 10/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 3.2814 - top_k_categorical_accuracy: 0.5265 - val_loss: 3.9842 - val_top_k_categorical_accuracy: 0.3509\n",
            "Epoch 11/16\n",
            "121/121 [==============================] - 5s 39ms/step - loss: 3.2541 - top_k_categorical_accuracy: 0.5312 - val_loss: 3.9227 - val_top_k_categorical_accuracy: 0.3644\n",
            "Epoch 12/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 3.2350 - top_k_categorical_accuracy: 0.5304 - val_loss: 3.9683 - val_top_k_categorical_accuracy: 0.3706\n",
            "Epoch 13/16\n",
            "121/121 [==============================] - 6s 51ms/step - loss: 3.1986 - top_k_categorical_accuracy: 0.5457 - val_loss: 3.9823 - val_top_k_categorical_accuracy: 0.3385\n",
            "Epoch 14/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 3.1950 - top_k_categorical_accuracy: 0.5483 - val_loss: 3.9444 - val_top_k_categorical_accuracy: 0.3613\n",
            "Epoch 15/16\n",
            "121/121 [==============================] - 5s 39ms/step - loss: 3.2104 - top_k_categorical_accuracy: 0.5338 - val_loss: 3.9637 - val_top_k_categorical_accuracy: 0.3385\n",
            "Epoch 16/16\n",
            "121/121 [==============================] - 5s 40ms/step - loss: 3.1928 - top_k_categorical_accuracy: 0.5405 - val_loss: 3.9189 - val_top_k_categorical_accuracy: 0.3623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Oxi58paHCA6Y",
        "outputId": "0bc0eff2-93e6-4845-8d9d-9db0d198ca13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f20b67d3ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there is not increment happened to the validation loss and the gap between the validation loss and the training loss is also not that big, indicating that the model is not overfitting. The Top-1 Accuracy of the model is also higher comparing to the other models that we have seen before, this pre-trained model is the best one so far as it is not overfitting and the Top-1 Accuracy is higher than the other ones. Some models that we have seen might score 90% of Top-1 Accuracy but then the model is overfitting so we cannot count them in. **We will go with this latest model at the end.**"
      ],
      "metadata": {
        "id": "7clFB8KKWbMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/AML\")"
      ],
      "metadata": {
        "id": "n1je-cMMiD7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}